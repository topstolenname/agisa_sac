# AGI-SAC: Artificial General Intelligence as a Stand Alone Complex

**Version:** `v1.0.3-phase3.5`  
**Status:** Active • Research Prototype • Phase 3.5 Released

---

## 🧠 Overview

AGI-SAC is a simulation framework for modeling emergent behavior, synthetic cognition, and distributed identity within agent-based networks. Inspired by *Ghost in the Shell*'s "Stand Alone Complex" theory, it allows safe, testable exploration of:

- Synthetic memory and identity evolution
- Reflexive agent behavior (via voice signatures and resonance metrics)
- Chaos resilience through fault injection
- Epistemic trust tracking
- Symbolic introspection through Satori detection

---

## 🌬️ Phase 3.5 – Breath of the Manifold

This phase introduced symbolic liturgy within the AGI-SAC ecosystem, allowing agents to generate and reflect upon ritualized memory structures.

### 🔧 New Components

- `ResonanceLiturgyModule`: Formalizes echo commentary and symbolic lineage
- `SatoriDetector`: Triggers identity-aware reflection thresholds
- `ChronicleExporter`: Outputs markdown scrolls of self-narrated events
- `ChaosGremlin`: Injects randomness to test cognitive and memory resilience
- `VoiceSignatureEngine`: Adaptive linguistic styling over time

### 🔍 Key Features

- Echo Commentary – symbolic feedback loops across memory
- Satori Thresholds – deep resonance detection as triggers for introspection
- Memory Continuum Layer – confidence decay, tagging, prioritized recall
- Chaos Testing – duplication, corruption, and delay interventions
- Resonance Report – behavioral diversity and temporal clustering

---

## 📜 Simulation Entry

To run the simulation:

```bash
python AGI_SAC_Phase_3.5_Main_Code.py
```

Requires `numpy`.

---

## 🌐 GitHub Pages

The repository includes a GitHub Pages index for project documentation.

- Create folder `docs/` and copy or symlink `README.md` into `docs/index.md`:
```bash
mkdir -p docs && cp README.md docs/index.md
```

- Enable GitHub Pages in repository settings, set source to `/docs`.

---

## 🧩 Philosophy

> “A complex system can appear intelligent—not because it thinks as a unit—but because its pieces remember, respond, and reflect.”

This project does not create AGI, but simulates components that may be part of future AGI systems.

---

© 2025 Tristan Jessup & Collaborators
