# Docent Tracing Integration - User Guide

## ‚úÖ What's Been Implemented

The Docent-style tracing infrastructure has been successfully integrated into AGI-SAC with full testing and validation.

### Core Components

1. **DocentTracer** (`src/agisa_sac/observability/docent_tracing.py`)
   - Main tracing class with OpenTelemetry integration
   - Graceful degradation when OpenTelemetry not available
   - Context managers for tracing LLM calls
   - Research metadata collection support

2. **LLM Client Wrappers** (`src/agisa_sac/llm/client_wrapper.py`)
   - `AnthropicTracedClient` - for Anthropic Claude API
   - `CustomModelTracedClient` - for custom/local models
   - Automatic trace collection for all LLM calls

3. **Instrumented Components**
   - `DistributedAgent._call_model()` - traces agent LLM calls
   - `VertexAgent.generate()` - traces Vertex AI calls
   - `VertexAILLM.query()` - traces Vertex AI helper calls

---

## üß™ Testing Results

All tests pass successfully:

```bash
$ python3 test_docent_integration.py
======================================================================
DOCENT TRACING INTEGRATION TEST
======================================================================

[Test 1] Importing docent_tracing module...
‚úì Successfully imported docent_tracing module

[Test 2] Initializing DocentTracer...
‚úì Successfully created DocentTracer

[Test 3] Testing trace_llm_call context manager...
‚úì Successfully recorded call result
‚úì Successfully recorded research metadata

[Test 4] Importing LLM client wrappers...
‚úì Successfully imported LLM client wrappers

[Test 5] Testing CustomModelTracedClient with mock LLM...
‚úì Successfully created CustomModelTracedClient

[Test 6] Testing async LLM call with tracing...
‚úì Successfully made async traced call

[Test 7] Testing graceful degradation...
‚úì Correctly raised ImportError when SDK missing

[Test 8] Checking DistributedAgent integration...
‚úì DistributedAgent has Docent tracing integration

[Test 9] Checking VertexAgent integration...
‚úì VertexAgent has Docent tracing integration

======================================================================
‚úì All basic tests passed!
======================================================================
```

---

## üìö Usage Examples

### Example 1: Basic Setup

```python
from agisa_sac.observability import setup_docent_tracing
from agisa_sac.llm import CustomModelTracedClient

# Initialize tracer
tracer = setup_docent_tracing(
    collection_name="my-simulation",
    enable_research_metrics=True
)

# Create traced client
async def my_llm(request):
    # Your LLM logic here
    return {"content": "response", "usage": {"total_tokens": 100}}

client = CustomModelTracedClient(
    tracer=tracer,
    model="my-model",
    llm_callable=my_llm
)

# Make traced call
result = await client({
    "messages": [{"role": "user", "content": "Hello"}]
})
```

### Example 2: With DistributedAgent

```python
from agisa_sac.observability import setup_docent_tracing

# Initialize tracer
tracer = setup_docent_tracing("agent-simulation", enable_research_metrics=True)

# Pass to agent via context
context = {
    "run_id": "run-001",
    "messages": [...],
    "llm_client": my_llm_client,
    "docent_tracer": tracer,  # ‚Üê Add tracer here
    "research_context": {      # ‚Üê Add research metadata
        "control_condition": False,
        "peer_influence": 0.7,
        "reputation_score": 0.85,
    }
}

# Agent will automatically trace LLM calls
result = await agent.run(message="...", context=context)
```

### Example 3: Anthropic API

```python
from agisa_sac.llm import AnthropicTracedClient
import os

tracer = setup_docent_tracing("anthropic-test")

client = AnthropicTracedClient(
    tracer=tracer,
    model="claude-sonnet-4-5-20250929",
    api_key=os.getenv("ANTHROPIC_API_KEY"),
    research_context={"experiment": "aim-1"}
)

result = await client({
    "model": "claude-sonnet-4-5-20250929",
    "messages": [{"role": "user", "content": "Hello!"}],
    "max_tokens": 100
})
```

---

## üîß Installation

To use the tracing features:

```bash
cd agisa_sac
pip install -e ".[tracing]"
```

This installs:
- `anthropic>=0.18.0` - Anthropic Claude SDK
- `opentelemetry-api>=1.20.0` - OpenTelemetry API
- `opentelemetry-sdk>=1.20.0` - OpenTelemetry SDK

---

## üìä What Gets Traced

### Standard Attributes
- `model` - Model identifier
- `usage.total_tokens` - Token count
- `num_messages` - Message count
- `num_tools` - Tool count
- `duration_ms` - Call duration
- `agent_id` - Agent identifier
- `run_id` - Run identifier

### Research Metadata (when enabled)
- `research.control_condition` - Control vs treatment flag
- `research.peer_influence` - Peer influence value
- `research.reputation_score` - Agent reputation
- `research.constraint_violations` - Violation count

---

## üîç Debugging

### Check if Tracing is Enabled

```python
from agisa_sac.observability.docent_tracing import HAS_OPENTELEMETRY
from agisa_sac.llm.client_wrapper import HAS_ANTHROPIC

print(f"OpenTelemetry available: {HAS_OPENTELEMETRY}")
print(f"Anthropic SDK available: {HAS_ANTHROPIC}")
```

### View Trace Data

When OpenTelemetry is installed, traces are exported to configured backends (e.g., Google Cloud Trace). Without OpenTelemetry, tracing metadata is still collected but only logged locally.

### Test Files

- `test_docent_integration.py` - Comprehensive integration tests
- `examples/docent_tracing_example.py` - Usage examples

---

## üöÄ Next Steps

The basic tracing infrastructure is complete and tested. To continue with full research instrumentation:

### Phase 3: Research Trace Collectors (Not Yet Implemented)
- `Aim1Collector` - Token distribution tracking
- `Aim2Collector` - Reputation score tracking
- `Aim3Collector` - Constraint violation tracking

### Phase 4: Analysis Module (Not Yet Implemented)
- `compute_kl_divergence_token_dist()` - KL divergence analysis
- `compute_reputation_instability()` - CUSUM changepoint detection
- `compute_constraint_entropy_timeseries()` - Entropy metrics

### Phase 5: CLI & Configuration (Not Yet Implemented)
- Research presets: `research-aim-1`, `research-aim-2`, `research-aim-3`
- CLI arguments: `--enable-tracing`, `--research-aim`, etc.
- `analyze-traces` command

### Phase 6: Tests & Examples (Not Yet Implemented)
- Unit tests for research metrics
- Integration tests for full simulation
- Example scripts for each research aim

**To continue**: Refer to `/home/tristanj/.claude/plans/zippy-gliding-bentley.md`

---

## üìù Files Modified

### New Files Created
- `src/agisa_sac/observability/docent_tracing.py`
- `src/agisa_sac/llm/__init__.py`
- `src/agisa_sac/llm/client_wrapper.py`
- `test_docent_integration.py`
- `examples/docent_tracing_example.py`
- `DOCENT_TRACING_GUIDE.md` (this file)

### Existing Files Modified
- `pyproject.toml` - Added dependencies
- `src/agisa_sac/observability/__init__.py` - Added exports
- `src/agisa_sac/gcp/distributed_agent.py` - Added tracing
- `src/agisa_sac/gcp/vertex_agent.py` - Added tracing
- `src/agisa_sac/gcp/mindlink_gcp_helpers.py` - Added tracing

---

## ‚úÖ Testing Checklist

- [x] Module imports work
- [x] DocentTracer initializes correctly
- [x] Context managers work
- [x] Result recording works
- [x] Research metadata recording works
- [x] LLM client wrappers work
- [x] Async calls work
- [x] Graceful degradation works
- [x] DistributedAgent integration works
- [x] VertexAgent integration works
- [x] Example scripts run successfully

All tests passing! ‚úÖ

---

## üêõ Known Issues

None currently! All tests pass.

---

## üìû Support

For questions or issues:
1. Check this guide first
2. Review test files for examples
3. Check implementation plan: `/home/tristanj/.claude/plans/zippy-gliding-bentley.md`
